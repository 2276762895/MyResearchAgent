import streamlit as st
import os
# --- ã€æ–°å¢ã€‘è®¾ç½®å›½å†…é•œåƒ ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
import tempfile
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA

import json
from pptx import Presentation


# --- âœ¨ æ–°å¢åŠŸèƒ½ï¼šPPT ç”Ÿæˆå‡½æ•° ---
def generate_ppt_file(topic, content_json):
    """
    è¾“å…¥ï¼šPPTä¸»é¢˜ï¼Œå’Œ DeepSeek ç”Ÿæˆçš„ JSON å†…å®¹
    è¾“å‡ºï¼šç”Ÿæˆçš„ PPT æ–‡ä»¶è·¯å¾„
    """
    try:
        # 1. åˆ›å»º PPT å¯¹è±¡
        prs = Presentation()

        # 2. è§£æ JSON æ•°æ®
        # æœ‰æ—¶å€™å¤§æ¨¡å‹ä¼šåŒ…è£¹ markdown ä»£ç å—ï¼Œéœ€è¦æ¸…æ´—
        clean_json = content_json.replace("```json", "").replace("```", "").strip()
        data = json.loads(clean_json)

        # 3. ç”Ÿæˆ å°é¢é¡µ
        slide_layout = prs.slide_layouts[0]  # 0 æ˜¯æ ‡é¢˜é¡µ
        slide = prs.slides.add_slide(slide_layout)
        slide.shapes.title.text = topic
        slide.placeholders[1].text = "Powered by DeepSeek & Python"

        # 4. å¾ªç¯ç”Ÿæˆ æ­£æ–‡é¡µ
        for page in data['pages']:
            slide_layout = prs.slide_layouts[1]  # 1 æ˜¯æ ‡é¢˜+å†…å®¹é¡µ
            slide = prs.slides.add_slide(slide_layout)

            # å¡«æ ‡é¢˜
            slide.shapes.title.text = page['title']

            # å¡«å†…å®¹ï¼ˆæŠŠåˆ—è¡¨å˜æˆå¸¦ç‚¹çš„æ–‡æœ¬ï¼‰
            tf = slide.placeholders[1].text_frame
            for point in page['content']:
                p = tf.add_paragraph()
                p.text = point
                p.level = 0

        # 5. ä¿å­˜æ–‡ä»¶
        output_path = "generated_ppt.pptx"
        prs.save(output_path)
        return output_path

    except Exception as e:
        st.error(f"PPTç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return None

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="ç§‘ç ”è®ºæ–‡æ™ºèƒ½åŠ©æ‰‹", layout="wide")
st.title("ğŸ“ è¯¾é¢˜ç»„ç§‘ç ”åŠ©æ‰‹ - æ–‡çŒ®é˜…è¯»ç‰ˆ")

# --- ä¾§è¾¹æ ï¼šè®¾ç½®ä¸æ–‡ä»¶ä¸Šä¼  ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    # è¾“å…¥ DeepSeek API Key
    api_key = st.text_input("è¯·è¾“å…¥ DeepSeek API Key", type="password")
    st.markdown("[ç‚¹å‡»ç”³è¯· DeepSeek API](https://platform.deepseek.com/)")

    st.divider()

    st.header("ğŸ“‚ ä¸Šä¼ æ–‡çŒ®")
    uploaded_file = st.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶", type=["pdf"])
    st.divider()
    st.header("ğŸ“Š ç”Ÿæˆæ±‡æŠ¥PPT")
    ppt_topic = st.text_input("è¯·è¾“å…¥PPTä¸»é¢˜", value="è®ºæ–‡æ±‡æŠ¥")

    if st.button("å¼€å§‹ç”Ÿæˆ PPT"):
        if not uploaded_file:
            st.warning("è¯·å…ˆä¸Šä¼ è®ºæ–‡PDFï¼")
        elif not api_key:
            st.warning("è¯·å¡«å†™ API Keyï¼")
        else:
            with st.spinner("DeepSeek æ­£åœ¨æ„æ€ PPT å¤§çº²..."):
                # 1. è®© DeepSeek ç”Ÿæˆ JSON æ•°æ®
                # è¿™é‡Œæˆ‘ä»¬åˆ©ç”¨å·²ç»å­˜åœ¨çš„ qa_chain (æ³¨æ„ï¼šéœ€è¦æŠŠ qa_chain è®¾ä¸ºå…¨å±€æˆ– session_stateï¼Œæˆ–è€…è¿™é‡Œä¸´æ—¶é‡æ–°å®šä¹‰)
                # ä¸ºäº†ç®€å•ç¨³å¦¥ï¼Œæˆ‘ä»¬ç›´æ¥å¤ç”¨ process_pdf è¿”å›çš„ chain
                if 'qa_chain' not in st.session_state:
                    # å¦‚æœç”¨æˆ·è¿˜æ²¡é—®è¿‡é—®é¢˜ï¼Œé“¾å¯èƒ½æ²¡å­˜ï¼Œè¿™é‡Œæˆ‘ä»¬å¾—ä» process_pdf å†æ‹¿ä¸€æ¬¡
                    # ä¸ºäº†ä»£ç ç®€æ´ï¼Œå»ºè®®ä½ å…ˆåœ¨ä¸»é€»è¾‘é‡ŒæŠŠ qa_chain å­˜è¿› st.session_state
                    st.warning("è¯·å…ˆåœ¨å³ä¾§ä¸»ç•Œé¢ç­‰å¾…è®ºæ–‡è¯»å–å®Œæˆï¼")
                else:
                    ppt_prompt = f"""
                        è¯·æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä¸ºä¸»é¢˜â€œ{ppt_topic}â€ç”Ÿæˆä¸€ä¸ªPPTå¤§çº²ã€‚
                        è¦æ±‚ï¼š
                        1. è¿”å›çº¯ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–åºŸè¯ã€‚
                        2. JSON æ ¼å¼å¿…é¡»å¦‚ä¸‹ï¼š
                        {{
                            "pages": [
                                {{"title": "ç ”ç©¶èƒŒæ™¯", "content": ["ç‚¹1", "ç‚¹2"]}},
                                {{"title": "æ ¸å¿ƒæ–¹æ³•", "content": ["ç‚¹1", "ç‚¹2"]}},
                                {{"title": "å®éªŒç»“æœ", "content": ["ç‚¹1", "ç‚¹2"]}},
                                {{"title": "ç»“è®º", "content": ["ç‚¹1", "ç‚¹2"]}}
                            ]
                        }}
                        3. è‡³å°‘ç”Ÿæˆ 5 é¡µ PPTã€‚
                        """

                    # è°ƒç”¨å¤§æ¨¡å‹
                    response = st.session_state.qa_chain.invoke({"query": ppt_prompt})
                    result_text = response["result"]

                    # 2. è°ƒç”¨ Python ç”»å›¾
                    ppt_path = generate_ppt_file(ppt_topic, result_text)

                    if ppt_path:
                        st.success("ğŸ‰ PPT ç”ŸæˆæˆåŠŸï¼")
                        with open(ppt_path, "rb") as f:
                            st.download_button(
                                label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½ PPT",
                                data=f,
                                file_name=f"{ppt_topic}.pptx",
                                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                            )


# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

@st.cache_resource
def process_pdf(file, api_key):
    if not file or not api_key:
        return None

    print("1. [å¼€å§‹] æ­£åœ¨ä¿å­˜ä¸´æ—¶æ–‡ä»¶...")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(file.getvalue())
        tmp_path = tmp_file.name

    print(f"2. [åŠ è½½] æ­£åœ¨è¯»å–PDF: {tmp_path} ...")
    loader = PyPDFLoader(tmp_path)
    docs = loader.load()
    print(f"   -> PDFè¯»å–å®Œæˆï¼Œå…± {len(docs)} é¡µ")

    print("3. [åˆ‡åˆ†] æ­£åœ¨åˆ‡åˆ†æ–‡æœ¬...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    print(f"   -> åˆ‡åˆ†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(splits)} ä¸ªæ–‡æœ¬å—")

    print("4. [æ¨¡å‹] æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹ (è¿™ä¸€æ­¥æœ€å®¹æ˜“å¡)...")
    try:
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        print("   -> æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"   -> âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise e

    print("5. [å­˜å‚¨] æ­£åœ¨å†™å…¥å‘é‡æ•°æ®åº“ (FAISS)...")
    try:
        # ä½¿ç”¨ FAISS æ›¿ä»£ Chromaï¼Œä¸éœ€è¦ SQLite æ”¯æŒï¼Œä¸ä¼šé—ªé€€
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        print("   -> æ•°æ®åº“å†™å…¥æˆåŠŸï¼(å·²åˆ‡æ¢ä¸º FAISS)")
    except Exception as e:
        print(f"   -> âŒ FAISS å†™å…¥å¤±è´¥: {e}")
        raise e

    print("6. [è¿æ¥] æ­£åœ¨åˆå§‹åŒ– DeepSeek...")
    llm = ChatOpenAI(
        model_name="deepseek-chat",
        openai_api_key=api_key,
        openai_api_base="https://api.deepseek.com",
        temperature=0.3
    )

    print("7. [å®Œæˆ] å‡†å¤‡å°±ç»ªï¼")

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True
    )

    os.remove(tmp_path)
    return qa_chain

# --- ä¸»ç•Œé¢é€»è¾‘ ---

if uploaded_file and api_key:
    with st.spinner("æ­£åœ¨é˜…è¯»è®ºæ–‡ï¼Œè¯·ç¨å€™... (ç¬¬ä¸€æ¬¡åŠ è½½æ¨¡å‹å¯èƒ½éœ€è¦1åˆ†é’Ÿ)"):
        # å¤„ç†PDF
        qa_chain = process_pdf(uploaded_file, api_key)
        # ã€æ–°å¢ã€‘æŠŠè¿™ä¸ªå·¥å…·å­˜åˆ° session_state é‡Œï¼Œè¿™æ ·ä¾§è¾¹æ ä¹Ÿèƒ½ç”¨
        st.session_state.qa_chain = qa_chain

    st.success("âœ… è®ºæ–‡å·²è¯»å–ï¼Œå¿«æ¥é—®æˆ‘é—®é¢˜å§ï¼")

    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # è·å–ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ"):
        # 1. æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # 2. è°ƒç”¨æ¨¡å‹å›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                response = qa_chain.invoke({"query": prompt})
                answer = response["result"]
                source_docs = response["source_documents"]

                # æ‹¼æ¥å¼•ç”¨æ¥æºï¼ˆå¯é€‰ï¼‰
                source_text = "\n\n> **å‚è€ƒç‰‡æ®µï¼š**\n"
                for i, doc in enumerate(source_docs):
                    source_text += f"> {i + 1}. Page {doc.metadata['page']}: {doc.page_content[:100]}...\n"

                full_response = answer + source_text
                st.markdown(full_response)

        # 3. ä¿å­˜åŠ©æ‰‹å›ç­”
        st.session_state.messages.append({"role": "assistant", "content": full_response})
        # åªæœ‰å½“æœ‰å¯¹è¯è®°å½•æ—¶æ‰æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
    if "messages" in st.session_state and len(st.session_state.messages) > 0:
        st.divider()  # ç”»ä¸€æ¡åˆ†å‰²çº¿

        # æŠŠå¯¹è¯è®°å½•è½¬æ¢æˆå­—ç¬¦ä¸²
        chat_history_text = ""
        for msg in st.session_state.messages:
            role = "æˆ‘" if msg["role"] == "user" else "AIåŠ©æ‰‹"
            chat_history_text += f"[{role}]: {msg['content']}\n\n"

        # ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ğŸ’¾ å¯¼å‡ºå¯¹è¯è®°å½• (ä¿å­˜ä¸ºTXT)",
            data=chat_history_text,
            file_name="è®ºæ–‡é˜…è¯»è®°å½•.txt",
            mime="text/plain"
        )

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥API Keyå¹¶ä¸Šä¼ PDFæ–‡ä»¶å¼€å§‹ã€‚")
